{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02357633-7f59-4916-98e8-270293a04aab",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?\n",
    "\n",
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766baa8e-81c7-4e5c-85a1-bbe7cce8c05a",
   "metadata": {},
   "source": [
    "Answer 1...\n",
    "\n",
    "Lasso Regression is a linear regression technique that uses L1 regularization to constrain the size of the coefficients in the model. Unlike other regression techniques, Lasso Regression can perform feature selection by setting the coefficients of irrelevant features to zero. This property of Lasso Regression makes it useful for dealing with high-dimensional datasets with many input features.\n",
    "\n",
    "Answer 2...\n",
    "\n",
    "The main advantage of using Lasso Regression in feature selection is that it can effectively reduce the dimensionality of the dataset by eliminating irrelevant features, which can improve the performance of the model and reduce overfitting. By setting the coefficients of some features to zero, Lasso Regression can also provide insights into the most important features in the dataset.\n",
    "\n",
    "Answer 3...\n",
    "\n",
    "The coefficients of a Lasso Regression model represent the strength and direction of the relationship between each input feature and the output variable. A positive coefficient indicates a positive relationship, while a negative coefficient indicates a negative relationship. The magnitude of the coefficient represents the strength of the relationship. The larger the absolute value of the coefficient, the stronger the relationship.\n",
    "\n",
    "Answer 4...\n",
    "\n",
    "The tuning parameter in Lasso Regression is the regularization parameter (lambda), which controls the strength of the L1 regularization penalty. Increasing lambda increases the strength of the penalty and shrinks the coefficients towards zero, which can improve the model's ability to generalize and reduce overfitting. However, setting lambda too high can result in underfitting, as the model may become too simple and fail to capture the underlying patterns in the data.\n",
    "\n",
    "ANswer 5...\n",
    "\n",
    "Yes, Lasso Regression can be used for non-linear regression problems by transforming the input features into a higher-dimensional space using kernel methods. This allows Lasso Regression to capture complex non-linear relationships between the input features and the output variable.\n",
    "\n",
    "Answer 6...\n",
    "\n",
    "The main difference between Ridge Regression and Lasso Regression is the type of regularization used. Ridge Regression uses L2 regularization to constrain the size of the coefficients, while Lasso Regression uses L1 regularization. This results in different penalty terms in the loss function and different effects on the size and sparsity of the coefficients. Ridge Regression tends to shrink all coefficients towards zero, while Lasso Regression can set some coefficients to exactly zero, resulting in feature selection.\n",
    "\n",
    "Answer 7...\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity in the input features by selecting one of the correlated features and setting the coefficients of the others to zero. This can help to reduce the complexity of the model and improve its ability to generalize.\n",
    "\n",
    "Answer 8...\n",
    "\n",
    "The optimal value of the regularization parameter (lambda) in Lasso Regression can be chosen using cross-validation. This involves dividing the dataset into training and validation sets, fitting the model with different values of lambda on the training set, and evaluating the performance of each model on the validation set. The value of lambda that gives the best performance on the validation set can then be selected as the optimal value. Alternatively, techniques such as the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) can be used to select the optimal value of lambda based on the trade-off between model complexity and goodness of fit.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c319d1-8c4d-44fd-ba59-33d1adf52d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
