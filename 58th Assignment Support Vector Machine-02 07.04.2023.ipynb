{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f9f6d5-9e53-4079-99c7-9a70cfd8e147",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b64a8e-00e9-4f49-9eed-bee4a2169b7b",
   "metadata": {},
   "source": [
    "Answer 1...\n",
    "\n",
    "Polynomial functions and kernel functions are related in machine learning algorithms because polynomial functions can be used as kernel functions in support vector machines (SVM). In SVM, the kernel function is used to map the input data into a higher-dimensional feature space where the data can be linearly separated. The polynomial kernel function is one of the commonly used kernel functions, which can be expressed as K(x, y) = (x*y + c)^d, where d is the degree of the polynomial and c is a constant. By using a polynomial kernel, the SVM can effectively separate non-linearly separable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69190399-2ed9-4f7d-870c-e5b8d17bcc2c",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6caa74-c4ef-4c07-824c-f1aeea0d46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2...\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d7582-3ead-467f-85c7-592ebcd63749",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060b129-75ac-4070-91f2-2ad0fe71ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data:\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e40a87-a0ec-488f-bf81-a10c7dcea595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SVC classifier with a polynomial kernel:\n",
    "\n",
    "svc_poly = SVC(kernel='poly', degree=3, gamma='scale', C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5612ae6-1bae-421c-9418-9fbc3f9f38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier on the training data:\n",
    "\n",
    "svc_poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e25e3-6fcb-4178-ae29-37fe075781a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained classifier to predict the labels of the testing data:\n",
    "\n",
    "y_pred = svc_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3ab50-8193-47a8-9385-09f7c926b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the classifier using any metric of your choice:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e99f1-5988-41f3-b271-7a1c959f2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to improve its performance:\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'degree': [2, 3, 4]}\n",
    "grid_search = GridSearchCV(svc_poly, param_grid=param_grid)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be6c40-4361-4ae3-b27b-0ceb8218ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tuned classifier on the entire dataset:\n",
    "\n",
    "svc_poly_tuned = grid_search.best_estimator_\n",
    "svc_poly_tuned.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bcef54-f400-448e-8e5d-6bbc08b5e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained classifier to a file for future use:\n",
    "\n",
    "import joblib\n",
    "joblib.dump(svc_poly_tuned, 'svc_poly_tuned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e961d19-c02b-4574-afba-1ffeab716100",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb48d00-4a3f-4c6f-9adb-6fbb5df64afb",
   "metadata": {},
   "source": [
    "Answer 3...\n",
    "\n",
    "Increasing the value of epsilon in Support Vector Regression (SVR) increases the number of support vectors. The epsilon parameter controls the width of the margin around the regression line, which is the region where no penalty is given for errors. The larger the value of epsilon, the wider the margin, and the more data points fall within it, which increases the number of support vectors. However, a larger number of support vectors can lead to longer training and prediction times and may overfit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c44fe7-10e0-4113-a187-76eb91e4e459",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1a4b1-1ae9-48fd-b15e-cda50b8087bb",
   "metadata": {},
   "source": [
    "Answer 4...\n",
    "\n",
    "The choice of kernel function, C parameter, epsilon parameter, and gamma parameter can significantly affect the performance of Support Vector Regression (SVR). Here's how each parameter works and some examples of when you might want to increase or decrease its value\n",
    "\n",
    "a) Kernel function: The kernel function determines the mapping of the input data to a higher-dimensional space and can greatly impact the flexibility of the decision boundary. For example, a linear kernel is less flexible than a polynomial or radial basis function (RBF) kernel, but may be more appropriate for linearly separable data.\n",
    "\n",
    "b)  parameter: The C parameter controls the trade-off between achieving a low training error and a low testing error. A smaller C allows for more margin violations and a wider margin, potentially resulting in more generalization to new data. A larger C penalizes margin violations more heavily and results in a narrower margin, potentially resulting in overfitting to the training data.\n",
    "\n",
    "c) Epsilon parameter: The epsilon parameter determines the margin of error allowed in the predictions, as described in Q3.\n",
    "\n",
    "d) Gamma parameter: The gamma parameter determines the width of the kernel and can greatly impact the flexibility of the decision boundary. A larger gamma results in a narrower kernel and potentially overfitting to the training data, while a smaller gamma results in a wider kernel and potentially underfitting.\n",
    "\n",
    "Examples of when you might want to increase or decrease the value of each parameter depend on the specific problem and data at hand, and often require tuning through experimentation and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e40ab-c07e-458c-9304-f0dbd5769f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
