{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af59dab-ffe9-4000-8d3c-aeb331d8ce02",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n",
    "\n",
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n",
    "\n",
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.\n",
    "\n",
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "\n",
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521849db-a846-4a70-9393-a75fdfd9a9bd",
   "metadata": {},
   "source": [
    "Answer 1...\n",
    "\n",
    "Simple linear regression is a statistical method used to establish a linear relationship between a dependent variable and one independent variable. On the other hand, multiple linear regression is used to establish a linear relationship between a dependent variable and two or more independent variables.\n",
    "\n",
    "For example, a simple linear regression model can be used to study the relationship between a person's age and their height, while a multiple linear regression model can be used to study the relationship between a person's age, weight, and height.\n",
    "\n",
    "Answer 2...\n",
    "\n",
    "The assumptions of linear regression include linearity, independence, homoscedasticity, normality, and absence of multicollinearity. We can check whether these assumptions hold in a given dataset through various methods such as visual inspection of scatterplots and residual plots, performing hypothesis tests, and examining correlation matrices and variance inflation factors.\n",
    "\n",
    "Answer 3...\n",
    "\n",
    "The slope in a linear regression model represents the change in the dependent variable for each one-unit change in the independent variable. The intercept represents the value of the dependent variable when the independent variable is zero.\n",
    "\n",
    "For example, in a linear regression model that examines the relationship between a person's years of experience and their salary, the slope represents the increase in salary for each additional year of experience, while the intercept represents the base salary that a person would receive with no experience.\n",
    "\n",
    "Answer 4...\n",
    "\n",
    "Gradient descent is an optimization algorithm used in machine learning to minimize the cost function of a model by iteratively adjusting the model parameters in the direction of the steepest descent. In other words, it finds the optimal set of parameters that best fit the data by minimizing the difference between the predicted and actual values.\n",
    "\n",
    "Answer 5...\n",
    "\n",
    "Multiple linear regression is a statistical method used to establish a linear relationship between a dependent variable and two or more independent variables. It differs from simple linear regression in that it allows for multiple independent variables to be included in the model and considers the effect of each independent variable on the dependent variable while controlling for the other variables.\n",
    "\n",
    "Answer 6...\n",
    "\n",
    "Multicollinearity refers to a situation where two or more independent variables in a multiple linear regression model are highly correlated, making it difficult to identify the independent effect of each variable on the dependent variable. It can be detected by examining the correlation matrix and variance inflation factors. To address this issue, one can either remove one of the highly correlated variables or combine them into a single variable.\n",
    "\n",
    "Answer 7...\n",
    "\n",
    "Polynomial regression is a statistical method used to establish a nonlinear relationship between a dependent variable and one or more independent variables by fitting a polynomial function to the data. It differs from linear regression in that it allows for a more flexible relationship between the dependent and independent variables, allowing for curved or nonlinear patterns.\n",
    "\n",
    "Answer 8...\n",
    "\n",
    "The advantage of polynomial regression over linear regression is that it can capture more complex relationships between the dependent and independent variables. However, the disadvantage is that it can overfit the data and may not generalize well to new data. Polynomial regression is preferred in situations where the relationship between the dependent and independent variables is not linear and has a curved or nonlinear pattern.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2f07c-e592-426c-9963-5102b14014f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
