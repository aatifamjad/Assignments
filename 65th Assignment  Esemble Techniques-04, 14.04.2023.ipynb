{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6a444b-66cf-4987-8b2d-fd2b01e960b9",
   "metadata": {},
   "source": [
    "Build a random forest classifier to predict the risk of heart disease based on a dataset of patient\n",
    "information. The dataset contains 303 instances with 14 features, including age, sex, chest pain type,\n",
    "resting blood pressure, serum cholesterol, and maximum heart rate achieved.\n",
    "Dataset link: https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?\n",
    "usp=share_link\n",
    "Q1. Preprocess the dataset by handling missing values, encoding categorical variables, and scaling the\n",
    "numerical features if necessary.\n",
    "\n",
    "Q2. Split the dataset into a training set (70%) and a test set (30%).\n",
    "\n",
    "Q3. Train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each\n",
    "tree. Use the default values for other hyperparameters.\n",
    "\n",
    "Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart\n",
    "disease risk. Visualise the feature importances using a bar chart.\n",
    "\n",
    "Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try\n",
    "different values of the number of trees, maximum depth, minimum samples split, and minimum samples\n",
    "leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters.\n",
    "\n",
    "Q7. Report the best set of hyperparameters found by the search and the corresponding performance\n",
    "metrics. Compare the performance of the tuned model with the default model.\n",
    "\n",
    "Q8. Interpret the model by analysing the decision boundaries of the random forest classifier. Plot the\n",
    "decision boundaries on a scatter plot of two of the most important features. Discuss the insights and\n",
    "limitations of the model for predicting heart disease risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9fe5bc-ea2b-4aa3-bcae-a4139fd8aa72",
   "metadata": {},
   "source": [
    "Answer 1...\n",
    "\n",
    "Preprocessing the dataset:\n",
    "\n",
    "First, we need to load the dataset and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcf93e-1398-47ab-98a7-bf3565b9aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv('heart.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07469ae7-8b3b-46cb-84b3-2682fdfe8b95",
   "metadata": {},
   "source": [
    "The dataset contains missing values represented by '?'. We will replace these values with NaNs and then drop the rows that contain missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3c9e4-1923-42af-962d-155bd7fead7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('?', np.nan)\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9d94a-30ba-40fb-bd8f-092a5e28c35c",
   "metadata": {},
   "source": [
    "Next, we will encode the categorical variables 'cp', 'restecg', 'slope', and 'thal' using LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38980e-8df2-408a-8544-94bf46691012",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['cp'] = encoder.fit_transform(df['cp'])\n",
    "df['restecg'] = encoder.fit_transform(df['restecg'])\n",
    "df['slope'] = encoder.fit_transform(df['slope'])\n",
    "df['thal'] = encoder.fit_transform(df['thal'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f8687-fe5b-4723-9026-903d8516c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, we will scale the numerical features using StandardScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64886344-f542-45ab-82ee-8632932ca667",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['age', 'trestbps', 'chol', 'thalach', 'oldpeak']] = scaler.fit_transform(df[['age', 'trestbps', 'chol', 'thalach', 'oldpeak']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a160d999-d116-49b4-acae-2ec1b7a1a73d",
   "metadata": {},
   "source": [
    "Q2. Split the dataset into a training set (70%) and a test set (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a5aed-5e40-455d-8367-ab2178e4e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2...\n",
    "\n",
    "# Splitting the dataset:\n",
    "\n",
    "# We will split the dataset into a training set (70%) and a test set (30%):\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278118c-16c5-45f1-ad4d-3f27d35bf9aa",
   "metadata": {},
   "source": [
    "Q3. Train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each\n",
    "tree. Use the default values for other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1e4fb-ce3c-4622-9513-89e1085fdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3...\n",
    "\n",
    "# Training the random forest classifier:\n",
    "\n",
    "# We will train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each tree:\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57990b11-22d0-40c3-a673-3ea813790e23",
   "metadata": {},
   "source": [
    "Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526e9d5-1e13-4dd5-8097-818cd334e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4...\n",
    "# Evaluating the performance of the model:\n",
    "\n",
    "# We will evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4f2eca-9278-4dce-a5fa-2865741b57ab",
   "metadata": {},
   "source": [
    "Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart\n",
    "disease risk. Visualise the feature importances using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825374b7-3637-48a8-811e-e6bca269eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5...\n",
    "\n",
    "# Identifying the top 5 most important features:\n",
    "\n",
    "# # We will use the feature importance scores to identify the top 5 most important features in predicting heart disease risk:\n",
    "\n",
    "\n",
    "\n",
    "importance_scores = rfc.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importance_scores})\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(feature_importances.head(5))\n",
    "\n",
    "\n",
    "# We can also visualize the feature importances using a bar chart:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(x=feature_importances['feature'], height=feature_importances['importance'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced3b45e-e006-4c9c-bf08-20e2a76688ee",
   "metadata": {},
   "source": [
    "Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try\n",
    "different values of the number of trees, maximum depth, minimum samples split, and minimum samples\n",
    "leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d65f81-effa-4482-af61-95e24581ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6...\n",
    "\n",
    "# Tuning hyperparameters using GridSearchCV:\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5f132-88fa-434e-8c6e-611937960064",
   "metadata": {},
   "source": [
    "Q7. Report the best set of hyperparameters found by the search and the corresponding performance\n",
    "metrics. Compare the performance of the tuned model with the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31616ac-a434-494f-bc3c-1ff768ef81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7...\n",
    "\n",
    "# Report the best set of hyperparameters found by the search and the corresponding performance metrics:\n",
    "\n",
    "# Using the above code, the best hyperparameters found by GridSearchCV are:\n",
    "\n",
    "Best parameters found: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb533c82-73ba-4460-b871-fff9af606f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can evaluate the performance of the tuned model using these hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be3eb9-c302-4254-8212-28ac9be4bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tuned_rfc = RandomForestClassifier(random_state=42, **best_params)\n",
    "tuned_rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tuned = tuned_rfc.predict(X_test)\n",
    "\n",
    "print(\"Classification report for tuned model:\\n\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bc3e4-4881-4050-b509-24e7ae88afdd",
   "metadata": {},
   "source": [
    "Q8. Interpret the model by analysing the decision boundaries of the random forest classifier. Plot the\n",
    "decision boundaries on a scatter plot of two of the most important features. Discuss the insights and\n",
    "limitations of the model for predicting heart disease risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c5846-9fee-4a99-8071-bcf42041af46",
   "metadata": {},
   "source": [
    "Answer 8...\n",
    "\n",
    "Interpret the model by analysing the decision boundaries of the random forest classifier:\n",
    "\n",
    "To plot the decision boundaries of the random forest classifier, we can select two of the most important features and create a scatter plot. We can then train the random forest classifier on the entire dataset and use it to predict the class probabilities for each point in the scatter plot. We can then visualize the decision boundaries by contouring the predicted class probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdd412-fa94-4d36-9f3a-d3146c9d9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select two most important features\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "feature_names = df.drop(columns=['target']).columns\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_feature_indices = indices[:2]\n",
    "top_feature_names = feature_names[top_feature_indices]\n",
    "X = X[:, top_feature_indices]\n",
    "\n",
    "# Train random forest classifier on entire dataset\n",
    "rfc.fit(X, y)\n",
    "\n",
    "# Create grid of points for scatter plot\n",
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "Z = rfc.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundaries and scatter plot\n",
    "plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu_r, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu_r, edgecolors='k')\n",
    "plt.xlabel(top_feature_names[0])\n",
    "plt.ylabel(top_feature_names[1])\n",
    "plt.title(\"Decision boundaries of random forest classifier\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd650e1-bf41-4e61-82d4-deffc7555771",
   "metadata": {},
   "source": [
    "The resulting plot will show the decision boundaries of the random forest classifier on the scatter plot of the two most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4e228-2f67-4984-9fb8-a7f0bbabb9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
