{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6913e5-0339-41cd-abc7-a239498e94d9",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Answer 1...\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory, named after the 18th-century statistician and philosopher Thomas Bayes. It provides a way to calculate the probability of an event based on prior knowledge or evidence related to that event.\n",
    "\n",
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Answer 2...\n",
    "\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the conditional probability of A given B\n",
    "P(B|A) is the conditional probability of B given A\n",
    "P(A) is the prior probability of A\n",
    "P(B) is the prior probability of B\n",
    "\n",
    "\n",
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Answer 3...\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, and artificial intelligence, to make predictions based on prior knowledge and new evidence. It is used to update prior beliefs or hypotheses with new data and to quantify uncertainty and risk.\n",
    "\n",
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Answer 4...\n",
    "\n",
    "Bayes' theorem and conditional probability are closely related concepts. Bayes' theorem provides a way to calculate the conditional probability of an event given some prior knowledge or evidence related to that event. Conditional probability, on the other hand, is the probability of an event given that another event has occurred.\n",
    "\n",
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Answer 5...\n",
    "\n",
    "\n",
    "The choice of which type of Naive Bayes classifier to use depends on the nature of the problem and the type of data available. The three main types of Naive Bayes classifiers are Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes.\n",
    "\n",
    "Gaussian Naive Bayes is used when the input features are continuous and have a normal distribution.\n",
    "Multinomial Naive Bayes is used when the input features are discrete and represent counts or frequencies.\n",
    "Bernoulli Naive Bayes is used when the input features are binary, representing the presence or absence of a particular feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe794af4-0762-48be-b9bf-4b9c357a89d7",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?\n",
    "\n",
    "\n",
    "Answer 6...\n",
    "\n",
    "To apply Naive Bayes to this problem, we need to calculate the posterior probabilities for each class given the new instance's features using Bayes' theorem.\n",
    "\n",
    "The prior probabilities for class A and class B are equal, so P(A) = P(B) = 0.5.\n",
    "\n",
    "To calculate the conditional probabilities, we can use the following formulas:\n",
    "\n",
    "P(X1=3|A) = 4/10 = 0.4\n",
    "P(X2=4|A) = 3/10 = 0.3\n",
    "P(X1=3|B) = 1/7 ≈ 0.143\n",
    "P(X2=4|B) = 1/7 ≈ 0.143\n",
    "\n",
    "Now we can use Bayes' theorem to calculate the posterior probabilities for each class:\n",
    "\n",
    "P(A|X1=3,X2=4) = P(X1=3|A) * P(X2=4|A) * P(A) / P(X1=3,X2=4)\n",
    "= 0.4 * 0.3 * 0.5 / P(X1=3,X2=4)\n",
    "\n",
    "P(B|X1=3,X2=4) = P(X1=3|B) * P(X2=4|B) * P(B) / P(X1=3,X2=4)\n",
    "= 0.143 * 0.143 * 0.5 / P(X1=3,X2=4)\n",
    "\n",
    "To calculate P(X1=3,X2=4), we can use the law of total probability:\n",
    "\n",
    "P(X1=3,X2=4) = P(X1=3|A) * P(X2=4|A) * P(A) + P(X1=3|B) * P(X2=4|B) * P(B)\n",
    "= 0.4 * 0.3 * 0.5 + 0.143 * 0.143 * 0.5\n",
    "= 0.042\n",
    "\n",
    "Therefore, we have:\n",
    "\n",
    "P(A|X1=3,X2=4) = 0.4 * 0.3 * 0.5 / 0.042 ≈ 0.571\n",
    "P(B|X1=3,X2=4) = 0.143 * 0.143 * 0.5 / 0.042 ≈ 0.190\n",
    "\n",
    "So Naive Bayes would predict that the new instance belongs to class A, since it has a higher posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9d0f6-fea0-40bc-b0fd-135509b6ad96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
