{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a835ea7-444a-4af0-81c3-62b613aaebb7",
   "metadata": {},
   "source": [
    "Q1. You are working on a mach#ne learning project where you have a dataset containing numerical and\n",
    "categorical features. You have identified that some of the features are highly correlated and there are\n",
    "missing values #n some of the columns. You want to build a pipeline that automates the feature\n",
    "engineering process and handles the m#ss#ng valuesD\n",
    "\n",
    "Design a pipeline that includes the following steps\"\n",
    "\n",
    "1) Use an automated feature selection method to identify the important features in the dataset\n",
    "2) Create a numerical pipeline that includes the follow#ng steps\"\n",
    "3) Impute the missing values in the numerical columns using the mean of the column valuesC\n",
    "4) Scale the numerical columns using standardisation\n",
    "5) Create a categorical pipeline that includes the following steps\"\n",
    "6) Impute the missing values in the categorical columns using the most frequent value of the columnC\n",
    "7) One-hot encode the categorical columnsC\n",
    "8) Combine the numerical and categorical pipelines using a ColumnTransformerC\n",
    "9) Use a Random Forest Classifier to build the final modelC\n",
    "10) Evaluate the accuracy of the model on the test datasetD\n",
    "\n",
    "Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of\n",
    "each step. You should also provide an interpretation of the results and suggest possible improvements for\n",
    "the pipelineD\n",
    "\n",
    "Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
    "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate #ts\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefc642-caf6-4485-ac10-d4a363ab143f",
   "metadata": {},
   "source": [
    "Answer 1...\n",
    "\n",
    "Building a Feature Engineering Pipeline\n",
    "\n",
    "The following code demonstrates the implementation of a pipeline that automates the feature engineering process and handles missing values. It uses an automated feature selection method, imputes missing values, scales numerical columns, imputes missing values in categorical columns, one-hot encodes categorical columns, combines numerical and categorical pipelines using ColumnTransformer, and finally uses a Random Forest Classifier to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d589a-89c3-4694-a97e-39bac17f96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Splitting the dataset into features and target variable\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Automated feature selection\n",
    "selector = SelectFromModel(RandomForestClassifier())\n",
    "selected_features = selector.fit_transform(X, y)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combining numerical and categorical pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_features),\n",
    "    ('cat', cat_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Creating the final pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Training the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the accuracy of the model on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4adf1b7-288c-4d16-b705-4de22c9a5487",
   "metadata": {},
   "source": [
    "Interpretation of Results:\n",
    "\n",
    "The pipeline automates the feature engineering process by using an automated feature selection method and handles missing values in both numerical and categorical columns. It scales the numerical columns using standardization and one-hot encodes the categorical columns. The selected features are then used to train a Random Forest Classifier model.\n",
    "\n",
    "The accuracy of the model on the test dataset is a measure of how well the model performs in making predictions. Higher accuracy indicates better performance. It is important to note that accuracy alone may not provide a complete picture of the model's performance, and additional evaluation metrics specific to the problem domain should be considered.\n",
    "\n",
    "Possible Improvements:\n",
    "\n",
    "Hyperparameter Tuning: You can optimize the hyperparameters of the Random Forest Classifier using techniques like grid search or random search to find the best combination of parameters.\n",
    "Feature Engineering: Explore additional feature engineering techniques such as polynomial features, interaction terms, or domain-specific transformations to improve the representation of the data.\n",
    "\n",
    "Handling Imbalanced Data: If the dataset is imbalanced, consider using techniques like oversampling or undersampling to address the class imbalance and improve model performance.\n",
    "Model Selection: Experiment with different classification algorithms apart from Random Forest, such as Gradient Boosting, Support Vector Machines, or Neural Networks, to compare their performance and select the best model for your dataset.\n",
    "Cross-Validation: Perform cross-validation to obtain a more reliable estimate of the model's performance and to check for overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b8894-85a1-422b-8755-c9e7af3f41e8",
   "metadata": {},
   "source": [
    "Certainly! To build a pipeline that includes a Random Forest Classifier and a Logistic Regression Classifier, and then use a Voting Classifier to combine their predictions, you can follow these steps:\n",
    "\n",
    "Step 1: Import the necessary libraries and load the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1479b1c5-e05e-4b0c-8e60-97858dc599f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f15bf-4a7f-4047-b78b-111db23db4d4",
   "metadata": {},
   "source": [
    "Step 2: Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ac4f6a-3a1a-416f-b70e-f76137986323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994595c-f9f3-4fa2-8320-8d5749218b57",
   "metadata": {},
   "source": [
    "Step 3: Create individual classifier instances for Random Forest and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5ab0d8-f87c-444f-98de-8bb8616aab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "logistic_regression = LogisticRegression(random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e8dd3e-de65-41f2-a5f0-3f68ec266da6",
   "metadata": {},
   "source": [
    "Step 4: Create a Voting Classifier that combines the individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8832b4-9aa6-4ecb-aa42-6d597d035494",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('rf', random_forest), ('lr', logistic_regression)],\n",
    "    voting='hard'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca6dcf-695b-4abd-977a-31ac90927a7f",
   "metadata": {},
   "source": [
    "Step 5: Create a pipeline that includes the Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e0b44d-0030-4d76-a74a-2250e6ecf3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('voting_classifier', voting_classifier)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6450a-02e3-47dc-a0e1-5d0daf188bef",
   "metadata": {},
   "source": [
    "Step 6: Train the pipeline on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed644596-aff3-4eb1-969e-ad6e995c5f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;voting_classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                               RandomForestClassifier(random_state=42)),\n",
       "                                              (&#x27;lr&#x27;,\n",
       "                                               LogisticRegression(random_state=42))]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;voting_classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                               RandomForestClassifier(random_state=42)),\n",
       "                                              (&#x27;lr&#x27;,\n",
       "                                               LogisticRegression(random_state=42))]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">voting_classifier: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                             (&#x27;lr&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('voting_classifier',\n",
       "                 VotingClassifier(estimators=[('rf',\n",
       "                                               RandomForestClassifier(random_state=42)),\n",
       "                                              ('lr',\n",
       "                                               LogisticRegression(random_state=42))]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc140d4-1021-44c2-b8d9-27b5c0cba006",
   "metadata": {},
   "source": [
    "Step 7: Evaluate the accuracy of the pipeline on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba0c995-d3f0-4816-a11d-8eac91d11e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b748e2f2-fdd9-4568-b1f5-29ae02f8dd5e",
   "metadata": {},
   "source": [
    "By following these steps, you will create a pipeline with a Random Forest Classifier and a Logistic Regression Classifier, and then use a Voting Classifier to combine their predictions. Finally, the accuracy of the pipeline on the testing data will be printed.\n",
    "\n",
    "Note: In Step 4, the voting parameter is set to 'hard', which means the class labels predicted by each individual classifier will be used to make the final prediction. You can also set it to 'soft', which takes into account the confidence levels of each classifier's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a1fc5-26a2-4d4b-9af3-8c66b12e6b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
